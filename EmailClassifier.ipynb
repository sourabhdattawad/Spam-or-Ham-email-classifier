{
 "metadata": {
  "name": "EmailClassifier"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import pandas as pd    \nfrom bs4 import BeautifulSoup \nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef content_to_words( raw_content ):\n\n    # Remove HTML\n    content_text = BeautifulSoup(raw_content).get_text() \n    # Remove non-letters        \n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", content_text) \n    # Convert to lower case, split into individual words\n    words = letters_only.lower().split()                             \n    # Stop words\n    stops = set(stopwords.words(\"english\"))                  \n    # Remove stop words\n    meaningful_words = [w for w in words if not w in stops]   \n\n    return( \" \".join( meaningful_words )) \n\n\ntrain = pd.read_csv(\"train_mail.csv\", header=0, delimiter=\"\\t\", quoting=0)\nnum_content = train[\"content\"].size\n\nprint \"Cleaning email content...\\n\"\nclean_train_content = []\nfor i in xrange( 0, num_content ):\n    if( (i+1)%1000 == 0 ):\n        print \"content %d of %d\\n\" % ( i+1, num_content )                                                                    \n    clean_train_content.append( content_to_words( train[\"content\"][i] ))\n\n\n# Initialize Vector\nvectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,stop_words = None, max_features = 1000) \ntrain_data_features = vectorizer.fit_transform(clean_train_content)\ntrain_data_features = train_data_features.toarray()\nprint train_data_features.shape\n\nprint \"Training the random forest...\"\n# Initialize a Random Forest classifier with 100 trees\nforest = RandomForestClassifier(n_estimators = 100) \nforest = forest.fit( train_data_features, train[\"spam\"] )\ntest = pd.read_csv(\"test_mail2.csv\", header=0, delimiter=\"\\t\", quoting=0 )\n\n\n\n# Clean test content\nnum_content = len(test[\"content\"])\nclean_test_content = [] \n\nprint \"Cleaning test email content...\\n\"\nfor i in xrange(0,num_content):\n    if( (i+1) % 1000 == 0 ):\n        print \"Content %d of %d\\n\" % (i+1, num_content)\n    clean_content = content_to_words( test[\"content\"][i] )\n    clean_test_content.append( clean_content )\n\n# Bag of words for the test set\ntest_data_features = vectorizer.transform(clean_test_content)\ntest_data_features = test_data_features.toarray()\n\n# Random forest prediction\nresult = forest.predict(test_data_features)\n\n# results to a pandas dataframe \noutput = pd.DataFrame( data={\"actual\":test[\"spam\"],\"predict\":result,\"content\":test[\"content\"] } )\n\n# write the to file\noutput.to_csv( \"afterpredict.csv\", index=False, quoting=0 )\nprint \"Done! Open output file.\"",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Cleaning email content...\n\ncontent 1000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 2000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 3000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 4000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 5000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 6000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 7000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 8000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 9000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 10000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 11000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 12000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 13000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 14000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 15000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": "WARNING:root:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 16000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 17000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 18000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 19000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 20000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 21000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 22000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 23000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 24000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\ncontent 25000 of 25000\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n(25000, 1000)"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nTraining the random forest...\nCleaning test email content...\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nDone! Open output file.\n"
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\n\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}